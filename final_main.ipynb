{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b7c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7402b05d-a334-43ca-a8d7-16fc1cfdd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import split, col, count, size, format_string, input_file_name, element_at\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "dataset_path = \"BDAchallenge2324\"\n",
    "output_path = \"results\"\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa487252-3a2d-4708-8ab4-e1bd5b8b75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(year, station):\n",
    "    dataframe = spark.read.format('csv') \\\n",
    "        .option('header', 'true') \\\n",
    "        .load('{}/{}/{}'.format(dataset_path, year, station)) \\\n",
    "        .withColumn('year', element_at(split(input_file_name(), '/'), -2).cast(\"string\")) \\\n",
    "        .withColumn('station', element_at(split(input_file_name(), \"/\"), -1).cast(\"string\")) \\\n",
    "        .withColumn('station', split(col('station'), '.csv')[0])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8321407-a1c9-4594-8750-7ec4bff551f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv(dataframe, file_name):\n",
    "    file_path = \"{}/{}\".format(output_path, file_name)\n",
    "    if not os.path.exists(file_path):\n",
    "        dataframe.coalesce(1).write.format(\"csv\").option(\"header\", \"true\").save(file_path)\n",
    "    else:\n",
    "        dataframe.coalesce(1).write.format(\"csv\").mode(\"overwrite\").option(\"header\", \"true\").save(file_path)\n",
    "    print(\"File .csv esportato con successo in: {}/{}\".format(output_path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c5f66c6-c65d-4148-baeb-cb21eca2c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_txt(file_name, result):\n",
    "    with open('{}/{}'.format(output_path, file_name), \"w\") as file:\n",
    "        if isinstance(result, list):\n",
    "           file.write(\"\\n\".join(result))\n",
    "        else:\n",
    "           file.write(result)\n",
    "    print(\"File .txt esportato con successo in: {}/{}\".format(output_path, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8837f",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bef1a4",
   "metadata": {},
   "source": [
    "#### Stampare il numero di misurazioni effettuate per ogni anno per ogni stazione (ordinato per anno e stazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910c3853-f1ca-4971-8030-259df85034c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_assignment(dataframe):\n",
    "    rows = []\n",
    "    output_dataframe = dataframe.select(\"year\", \"station\") \\\n",
    "        .groupBy(\"year\", \"station\") \\\n",
    "        .agg(count(\"*\").alias(\"measures_count\")) \\\n",
    "        .orderBy(\"year\", \"station\") \n",
    "    for row in output_dataframe.collect():\n",
    "        row_values = \"{}, {}, {}\".format(row[\"year\"], row[\"station\"], row[\"measures_count\"])\n",
    "        print(row_values)\n",
    "        rows.append(row_values)\n",
    "    export_txt(\"task1.txt\", rows)\n",
    "    export_csv(output_dataframe, \"task1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c10982",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f5021",
   "metadata": {},
   "source": [
    "#### Stampare le prime 10 temperature (TMP) con il maggior numero di occorrenze ed il relativo conteggio registrate nell’area         evidenziata (ordinate per numero di occorrenze e temperatura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa94b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_assignment(dataframe):\n",
    "    rows = []\n",
    "    output_dataframe = dataframe \\\n",
    "        .filter((col(\"LATITUDE\").between(30, 60)) & (col(\"LONGITUDE\").between(-135, -90))) \\\n",
    "        .groupBy(\"TMP\") \\\n",
    "        .agg(count(\"*\").alias(\"TMP_count\")) \\\n",
    "        .orderBy(col(\"TMP_count\").desc(), col(\"TMP\").desc()) \\\n",
    "        .limit(10)\n",
    "    for row in output_dataframe.collect():\n",
    "        row_values = \"[(60,-135);(30,-90)], {}, {}\".format(float(row[\"TMP\"][1:].replace(',', '.')), row[\"TMP_count\"])\n",
    "        print(row_values)\n",
    "        rows.append(row_values)\n",
    "    export_txt(\"task2.txt\", rows)\n",
    "    export_csv(output_dataframe, \"task2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037c53f-d971-4508-89ac-cf252e76e697",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573f15d-ffc2-41dd-adc0-ca57c10f03fd",
   "metadata": {},
   "source": [
    "#### Stampare la stazione con la velocità in nodi che occorre più volte ed il relativo conteggio (ordinando per conteggio, velocità e stazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f16a6cf-9a14-41b0-b7e7-e61309ffff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_assignment(dataframe):\n",
    "    output_dataframe = dataframe \\\n",
    "        .withColumn('WDN_speed', split(col('WND'), ',')[1]) \\\n",
    "        .groupBy('station', 'WDN_speed') \\\n",
    "        .agg(count('*').alias('WND_speed_count')) \\\n",
    "        .orderBy(col(\"WND_speed_count\").desc(), col(\"WDN_speed\").desc(), col(\"station\").asc()) \\\n",
    "        .limit(1) \n",
    "    result = \"{}, {}, {}\".format(output_dataframe.collect()[0][\"station\"], \\\n",
    "                                 output_dataframe.collect()[0][\"WDN_speed\"], \\\n",
    "                                 output_dataframe.collect()[0][\"WND_speed_count\"])\n",
    "    print(result)\n",
    "    export_txt(\"task3.txt\", result)\n",
    "    export_csv(output_dataframe, \"task3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5abc2-129a-4823-9331-f7f2950b0456",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de24bc64-2f3d-4396-93de-9d5f59041233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000, 99999994988, 316\n",
      "2000, 99999994989, 316\n",
      "2000, 99999994991, 316\n",
      "2000, 99999994992, 316\n",
      "2000, 99999994993, 316\n",
      "2000, 99999994994, 316\n",
      "2001, 99999994988, 375\n",
      "2001, 99999994989, 375\n",
      "2001, 99999994992, 375\n",
      "2001, 99999994993, 375\n",
      "2001, 99999994994, 375\n",
      "2002, 01092099999, 2805\n",
      "2002, 02328099999, 1\n",
      "2002, 02508099999, 4\n",
      "2002, 02602099999, 2698\n",
      "2002, 02869099999, 16848\n",
      "2002, 03118099999, 2\n",
      "2002, 03604099999, 8413\n",
      "2002, 04212099999, 6\n",
      "2002, 06021099999, 1381\n",
      "2003, 02602099999, 2706\n",
      "2003, 15318099999, 1\n",
      "2003, 57328099999, 2872\n",
      "2003, 68377099999, 1251\n",
      "2003, 72410499999, 18293\n",
      "2003, 89266099999, 652\n",
      "2003, 95658099999, 2822\n",
      "2003, 99640099999, 8466\n",
      "2003, 99689099999, 3\n",
      "2004, 02328099999, 1\n",
      "2004, 02602099999, 2603\n",
      "2004, 57328099999, 2899\n",
      "2004, 68377099999, 1322\n",
      "2004, 71393099999, 392\n",
      "2004, 72410499999, 18616\n",
      "2004, 95658099999, 2839\n",
      "2004, 99640099999, 8594\n",
      "2004, 99689099999, 2\n",
      "File .txt esportato con successo in: results/task1.txt\n",
      "File .csv esportato con successo in: results/task1.csv\n",
      "[(60,-135);(30,-90)], 9999.9, 4468\n",
      "[(60,-135);(30,-90)], 141.1, 455\n",
      "[(60,-135);(30,-90)], 144.1, 409\n",
      "[(60,-135);(30,-90)], 149.1, 372\n",
      "[(60,-135);(30,-90)], 145.1, 360\n",
      "[(60,-135);(30,-90)], 136.1, 358\n",
      "[(60,-135);(30,-90)], 160.1, 346\n",
      "[(60,-135);(30,-90)], 156.1, 344\n",
      "[(60,-135);(30,-90)], 157.1, 335\n",
      "[(60,-135);(30,-90)], 137.1, 329\n",
      "File .txt esportato con successo in: results/task2.txt\n",
      "File .csv esportato con successo in: results/task2.csv\n",
      "72410499999, 9, 29108\n",
      "File .txt esportato con successo in: results/task3.txt\n",
      "File .csv esportato con successo in: results/task3.csv\n",
      "Tempo di completamento: 14.008203983306885 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    starting_time = time()\n",
    "    schema = StructType([])\n",
    "    total_dataframe = spark.createDataFrame([], schema)\n",
    "    for root, dirs, files in sorted(os.walk((dataset_path))):\n",
    "        for file in sorted(files):\n",
    "            if (file == \".DS_Store\"):\n",
    "                continue\n",
    "            dataframe = read_csv(os.path.basename(root), file)\n",
    "            total_dataframe = total_dataframe.unionByName(dataframe, allowMissingColumns=True)\n",
    "    first_assignment(total_dataframe)\n",
    "    second_assignment(total_dataframe)\n",
    "    third_assignment(total_dataframe)\n",
    "    print(\"Tempo di completamento: {} seconds.\".format(time() - starting_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
